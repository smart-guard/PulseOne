// =============================================================================
// collector/include/Pipeline/PipelineManager.h - ë©€í‹°ìŠ¤ë ˆë“œ ê°œì„ 
// =============================================================================
#ifndef PULSEONE_PIPELINE_MANAGER_H
#define PULSEONE_PIPELINE_MANAGER_H

#include "Common/Structs.h"
#include "Pipeline/DataProcessingService.h"
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include <memory>
#include <vector>

namespace PulseOne {
namespace Pipeline {

/**
 * @brief ë©€í‹°ìŠ¤ë ˆë“œ ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € (ì‹±ê¸€í†¤)
 * @details ğŸ”¥ ë³‘ëª© í•´ê²°: 1ê°œ í + Nê°œ ì²˜ë¦¬ ìŠ¤ë ˆë“œë¡œ ë³‘ë ¬ ì²˜ë¦¬
 */
class PipelineManager {
public:
    // ==========================================================================
    // ğŸ”¥ ì‹±ê¸€í†¤ íŒ¨í„´
    // ==========================================================================
    
    static PipelineManager& GetInstance() {
        static PipelineManager instance;
        return instance;
    }
    
    // ë³µì‚¬/ì´ë™/ëŒ€ì… ë°©ì§€
    PipelineManager(const PipelineManager&) = delete;
    PipelineManager& operator=(const PipelineManager&) = delete;
    PipelineManager(PipelineManager&&) = delete;
    PipelineManager& operator=(PipelineManager&&) = delete;

    // ==========================================================================
    // ğŸ”¥ ì „ì—­ ì´ˆê¸°í™”
    // ==========================================================================
    
    bool Initialize(
        std::shared_ptr<RedisClient> redis_client,
        std::shared_ptr<InfluxClient> influx_client = nullptr,
        size_t processing_threads = 0  // 0 = CPU ì½”ì–´ ìˆ˜ ìë™
    );
    
    bool Start();
    void Shutdown();
    
    bool IsInitialized() const { return is_initialized_.load(); }
    bool IsRunning() const { return is_running_.load(); }

    // ==========================================================================
    // ğŸ”¥ Worker ì¸í„°í˜ì´ìŠ¤ (ë³€ê²½ ì—†ìŒ)
    // ==========================================================================
    
    bool SendDeviceData(
        const std::string& device_id,
        const std::vector<Structs::TimestampedValue>& values,
        const std::string& worker_id = "unknown",
        uint32_t priority = 0
    );
    
    // ==========================================================================
    // ğŸ”¥ ëª¨ë‹ˆí„°ë§
    // ==========================================================================
    
    struct PipelineStats {
        uint64_t total_received = 0;
        uint64_t total_processed = 0;
        uint64_t total_dropped = 0;
        size_t current_queue_size = 0;
        uint64_t redis_writes = 0;
        double avg_processing_time_ms = 0.0;
        size_t active_processing_threads = 0;  // í™œì„± ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
    };
    
    PipelineStats GetStatistics() const;
    void ResetStatistics();

private:
    PipelineManager() = default;
    ~PipelineManager() { Shutdown(); }

    // ==========================================================================
    // ğŸ”¥ ë©€í‹°ìŠ¤ë ˆë“œ í ì²˜ë¦¬ ì‹œìŠ¤í…œ
    // ==========================================================================
    
    // ì´ˆê¸°í™” ìƒíƒœ
    std::atomic<bool> is_initialized_{false};
    std::atomic<bool> is_running_{false};
    std::atomic<bool> should_stop_{false};
    
    // ğŸ”¥ ê³µìœ  í (1ê°œ) + ë©€í‹°ìŠ¤ë ˆë“œ ì²˜ë¦¬ (Nê°œ)
    std::queue<Structs::DeviceDataMessage> global_queue_;
    mutable std::mutex queue_mutex_;
    std::condition_variable queue_cv_;
    
    // ğŸ”¥ ë©€í‹° ì²˜ë¦¬ ìŠ¤ë ˆë“œë“¤
    std::vector<std::thread> processing_threads_;
    size_t num_processing_threads_ = 4;  // ê¸°ë³¸ 4ê°œ ìŠ¤ë ˆë“œ
    
    // ğŸ”¥ DataProcessingService (ìŠ¤ë ˆë“œ ì•ˆì „)
    std::shared_ptr<DataProcessingService> data_processing_service_;
    
    // ì„¤ì •
    size_t max_queue_size_ = 100000;
    size_t batch_size_ = 500;
    
    // í†µê³„
    std::atomic<uint64_t> total_received_{0};
    std::atomic<uint64_t> total_processed_{0};
    std::atomic<uint64_t> total_dropped_{0};
    std::atomic<size_t> current_queue_size_{0};
    
    // ==========================================================================
    // ğŸ”¥ ë©€í‹°ìŠ¤ë ˆë“œ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    // ==========================================================================
    
    /**
     * @brief ê° ì²˜ë¦¬ ìŠ¤ë ˆë“œì˜ ë£¨í”„ (Nê°œ ìŠ¤ë ˆë“œê°€ ë³‘ë ¬ ì‹¤í–‰)
     */
    void ProcessingThreadLoop(size_t thread_id);
    
    /**
     * @brief íì—ì„œ ë°°ì¹˜ ìˆ˜ì§‘ (ìŠ¤ë ˆë“œ ì•ˆì „)
     */
    std::vector<Structs::DeviceDataMessage> CollectBatch(size_t thread_id);
};

} // namespace Pipeline
} // namespace PulseOne

#endif // PULSEONE_PIPELINE_MANAGER_H

// =============================================================================
// collector/src/Pipeline/PipelineManager.cpp - ë©€í‹°ìŠ¤ë ˆë“œ êµ¬í˜„
// =============================================================================
#include "Pipeline/PipelineManager.h"
#include "Utils/LogManager.h"
#include <chrono>
#include <algorithm>

namespace PulseOne {
namespace Pipeline {

// =============================================================================
// ğŸ”¥ ì´ˆê¸°í™” - ë©€í‹°ìŠ¤ë ˆë“œ ì„¤ì •
// =============================================================================

bool PipelineManager::Initialize(
    std::shared_ptr<RedisClient> redis_client,
    std::shared_ptr<InfluxClient> influx_client,
    size_t processing_threads) {
    
    if (is_initialized_.load()) {
        LogManager::getInstance().Warn("âš ï¸ PipelineManager already initialized");
        return true;
    }
    
    LogManager::getInstance().Info("ğŸš€ PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì´ˆê¸°í™” ì‹œì‘...");
    
    try {
        // ğŸ”¥ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜ ê²°ì •
        if (processing_threads == 0) {
            // CPU ì½”ì–´ ìˆ˜ ê¸°ë°˜ (ìµœì†Œ 2ê°œ, ìµœëŒ€ 8ê°œ)
            num_processing_threads_ = std::max(2u, std::min(8u, std::thread::hardware_concurrency()));
        } else {
            num_processing_threads_ = std::max(1u, std::min(16u, processing_threads));
        }
        
        LogManager::getInstance().Info("ğŸ”§ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜: {}ê°œ", num_processing_threads_);
        
        // DataProcessingService ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)
        data_processing_service_ = std::make_shared<DataProcessingService>(
            redis_client, influx_client);
        
        is_initialized_ = true;
        
        LogManager::getInstance().Info("âœ… PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì´ˆê¸°í™” ì™„ë£Œ");
        LogManager::getInstance().Info("ğŸ“Š ì„¤ì • - í: {}, ë°°ì¹˜: {}, ìŠ¤ë ˆë“œ: {}ê°œ", 
                                     max_queue_size_, batch_size_, num_processing_threads_);
        
        return true;
        
    } catch (const std::exception& e) {
        LogManager::getInstance().Error("âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e.what());
        return false;
    }
}

bool PipelineManager::Start() {
    if (!is_initialized_.load()) {
        LogManager::getInstance().Error("âŒ PipelineManager not initialized!");
        return false;
    }
    
    if (is_running_.load()) {
        LogManager::getInstance().Warn("âš ï¸ PipelineManager already running");
        return true;
    }
    
    LogManager::getInstance().Info("ğŸš€ PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì‹œì‘...");
    
    try {
        // DataProcessingService ì‹œì‘
        if (!data_processing_service_->Start()) {
            LogManager::getInstance().Error("âŒ DataProcessingService ì‹œì‘ ì‹¤íŒ¨");
            return false;
        }
        
        is_running_ = true;
        should_stop_ = false;
        
        // ğŸ”¥ Nê°œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
        processing_threads_.clear();
        processing_threads_.reserve(num_processing_threads_);
        
        for (size_t i = 0; i < num_processing_threads_; ++i) {
            processing_threads_.emplace_back(&PipelineManager::ProcessingThreadLoop, this, i);
            LogManager::getInstance().Debug("ğŸ§µ ì²˜ë¦¬ ìŠ¤ë ˆë“œ {} ì‹œì‘ë¨", i);
        }
        
        LogManager::getInstance().Info("âœ… PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì‹œì‘ ì™„ë£Œ ({}ê°œ ìŠ¤ë ˆë“œ)", 
                                     num_processing_threads_);
        
        return true;
        
    } catch (const std::exception& e) {
        LogManager::getInstance().Error("âŒ PipelineManager ì‹œì‘ ì‹¤íŒ¨: {}", e.what());
        return false;
    }
}

void PipelineManager::Shutdown() {
    if (!is_running_.load()) {
        return;
    }
    
    LogManager::getInstance().Info("ğŸ›‘ PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹œì‘...");
    
    should_stop_ = true;
    queue_cv_.notify_all();  // ëª¨ë“  ìŠ¤ë ˆë“œ ê¹¨ìš°ê¸°
    
    // ğŸ”¥ ëª¨ë“  ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
    for (size_t i = 0; i < processing_threads_.size(); ++i) {
        if (processing_threads_[i].joinable()) {
            processing_threads_[i].join();
            LogManager::getInstance().Debug("ğŸ§µ ì²˜ë¦¬ ìŠ¤ë ˆë“œ {} ì¢…ë£Œë¨", i);
        }
    }
    processing_threads_.clear();
    
    // DataProcessingService ì¢…ë£Œ
    if (data_processing_service_) {
        data_processing_service_->Stop();
    }
    
    is_running_ = false;
    
    LogManager::getInstance().Info("âœ… PipelineManager ë©€í‹°ìŠ¤ë ˆë“œ ì¢…ë£Œ ì™„ë£Œ");
    LogManager::getInstance().Info("ğŸ“Š ìµœì¢… í†µê³„ - ë°›ìŒ: {}, ì²˜ë¦¬: {}, ëˆ„ë½: {}", 
                                 total_received_.load(), total_processed_.load(), total_dropped_.load());
}

// =============================================================================
// ğŸ”¥ Worker ì¸í„°í˜ì´ìŠ¤ (ë³€ê²½ ì—†ìŒ)
// =============================================================================

bool PipelineManager::SendDeviceData(
    const std::string& device_id,
    const std::vector<Structs::TimestampedValue>& values,
    const std::string& worker_id,
    uint32_t priority) {
    
    if (!is_running_.load() || values.empty()) {
        return false;
    }
    
    // DeviceDataMessage ìƒì„±
    Structs::DeviceDataMessage message;
    message.device_id = device_id;
    message.protocol = "AUTO_DETECTED";
    message.points = values;
    message.priority = priority;
    message.timestamp = std::chrono::system_clock::now();
    
    // ğŸ”¥ ê³µìœ  íì— ì¶”ê°€ (ìŠ¤ë ˆë“œ ì•ˆì „)
    {
        std::lock_guard<std::mutex> lock(queue_mutex_);
        
        // í ì˜¤ë²„í”Œë¡œìš° ì²´í¬
        if (global_queue_.size() >= max_queue_size_) {
            total_dropped_.fetch_add(1);
            LogManager::getInstance().Warn("âŒ ì „ì—­ í ì˜¤ë²„í”Œë¡œìš°, ë°ì´í„° ëˆ„ë½: {} (Worker: {})", 
                                         device_id, worker_id);
            return false;
        }
        
        // íì— ì¶”ê°€
        global_queue_.push(std::move(message));
        current_queue_size_.store(global_queue_.size());
    }
    
    // ğŸ”¥ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ë ˆë“œ í•˜ë‚˜ ê¹¨ìš°ê¸°
    queue_cv_.notify_one();
    
    // í†µê³„ ì—…ë°ì´íŠ¸
    total_received_.fetch_add(1);
    
    LogManager::getInstance().Debug("âœ… [{}] ë””ë°”ì´ìŠ¤ {} ë°ì´í„° ì „ì—­í ì¶”ê°€ ({}ê°œ í¬ì¸íŠ¸)", 
                                   worker_id, device_id, values.size());
    return true;
}

// =============================================================================
// ğŸ”¥ ë©€í‹°ìŠ¤ë ˆë“œ ì²˜ë¦¬ ë£¨í”„
// =============================================================================

void PipelineManager::ProcessingThreadLoop(size_t thread_id) {
    LogManager::getInstance().Info("ğŸ§µ ì²˜ë¦¬ ìŠ¤ë ˆë“œ {} ì‹œì‘", thread_id);
    
    while (!should_stop_.load()) {
        try {
            // ğŸ”¥ íì—ì„œ ë°°ì¹˜ ìˆ˜ì§‘ (ìŠ¤ë ˆë“œ ê²½ìŸ)
            auto batch = CollectBatch(thread_id);
            
            if (!batch.empty()) {
                auto start_time = std::chrono::high_resolution_clock::now();
                
                // ğŸ”¥ DataProcessingServiceì— ë°°ì¹˜ ì „ë‹¬
                if (data_processing_service_) {
                    data_processing_service_->ProcessBatch(batch);
                    total_processed_.fetch_add(batch.size());
                    
                    auto end_time = std::chrono::high_resolution_clock::now();
                    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
                    
                    LogManager::getInstance().Debug("ğŸ§µ ìŠ¤ë ˆë“œ {} ë°°ì¹˜ ì²˜ë¦¬: {}ê°œ ë©”ì‹œì§€, {}Î¼s", 
                                                   thread_id, batch.size(), duration.count());
                } else {
                    LogManager::getInstance().Error("âŒ DataProcessingService ì—†ìŒ! (ìŠ¤ë ˆë“œ {})", thread_id);
                }
            }
            
        } catch (const std::exception& e) {
            LogManager::getInstance().Error("ğŸ’¥ ìŠ¤ë ˆë“œ {} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {}", thread_id, e.what());
            // ì˜ˆì™¸ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ê³„ì†
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        }
    }
    
    LogManager::getInstance().Info("ğŸ§µ ì²˜ë¦¬ ìŠ¤ë ˆë“œ {} ì¢…ë£Œ", thread_id);
}

std::vector<Structs::DeviceDataMessage> PipelineManager::CollectBatch(size_t thread_id) {
    std::vector<Structs::DeviceDataMessage> batch;
    batch.reserve(batch_size_);
    
    std::unique_lock<std::mutex> lock(queue_mutex_);
    
    // ğŸ”¥ ë°ì´í„°ê°€ ìˆê±°ë‚˜ ì¢…ë£Œ ì‹ í˜¸ê¹Œì§€ ëŒ€ê¸°
    queue_cv_.wait(lock, [this] {
        return !global_queue_.empty() || should_stop_.load();
    });
    
    // ğŸ”¥ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ìˆ˜ì§‘ (ìŠ¤ë ˆë“œë“¤ì´ ê²½ìŸì ìœ¼ë¡œ ê°€ì ¸ê°)
    while (!global_queue_.empty() && batch.size() < batch_size_) {
        batch.push_back(std::move(global_queue_.front()));
        global_queue_.pop();
    }
    
    current_queue_size_.store(global_queue_.size());
    
    if (!batch.empty()) {
        LogManager::getInstance().Debug("ğŸ§µ ìŠ¤ë ˆë“œ {} ë°°ì¹˜ ìˆ˜ì§‘: {}ê°œ ë©”ì‹œì§€ (í ë‚¨ì€ í¬ê¸°: {})", 
                                       thread_id, batch.size(), global_queue_.size());
    }
    
    return batch;
}

// =============================================================================
// ğŸ”¥ í†µê³„
// =============================================================================

PipelineManager::PipelineStats PipelineManager::GetStatistics() const {
    PipelineStats stats;
    stats.total_received = total_received_.load();
    stats.total_processed = total_processed_.load();
    stats.total_dropped = total_dropped_.load();
    stats.current_queue_size = current_queue_size_.load();
    stats.active_processing_threads = processing_threads_.size();
    
    return stats;
}

void PipelineManager::ResetStatistics() {
    total_received_ = 0;
    total_processed_ = 0;
    total_dropped_ = 0;
    current_queue_size_ = 0;
    
    LogManager::getInstance().Info("ğŸ“Š PipelineManager í†µê³„ ë¦¬ì…‹ë¨");
}

} // namespace Pipeline
} // namespace PulseOne